{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt # data visualization\n","import seaborn as sns # data visualization\n","\n","from sklearn.model_selection import train_test_split\n","from keras.utils.np_utils import to_categorical\n","\n","import tensorflow as tf\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Conv2D, Dropout, Dense, Flatten, BatchNormalization, MaxPooling2D,LeakyReLU\n","from keras.optimizers import RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping,ModelCheckpoint\n","from keras.utils.np_utils import to_categorical\n","from tensorflow.keras.regularizers import l2\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["nets = 5\n","model = [0] *(nets)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["raw_train = pd.read_csv('../input/Kannada-MNIST/train.csv')\n","raw_test = pd.read_csv('../input/Kannada-MNIST/test.csv')\n","\n","import random\n","random.seed(0)\n","np.random.seed(0)\n","import tensorflow as tf\n","tf.compat.v1.set_random_seed(0)\n","# only can fix train data, still have some difference because of GPU training"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def SelfKFold(raw_train):\n","    '''\n","    return n train and val dataset.\n","    '''\n","    from sklearn.model_selection import KFold\n","    raw_train_val = raw_train\n","    random_train_val = raw_train_val.sample(frac=1).reset_index(drop=True)#need fix np.random\n","    kfold = KFold(n_splits=5,random_state=None)\n","    train_val_data = raw_train_val.drop('label',axis = 1).values.astype(np.uint8)\n","    train_val_label = raw_train_val['label'].values.astype(np.uint8)\n","    print('data shape:', train_val_data.shape)\n","    print('label shape:', train_val_label.shape)\n","    train_total = []\n","    train_label_total = []\n","    val_total = []\n","    val_label_total = []\n","    for _,val_index in kfold.split(train_val_data,train_val_label):\n","        print('val data index:',val_index[0],val_index[-1])\n","        train_sub_0 = train_val_data[val_index[-1]+1:]\n","        train_sub_1 = train_val_data[:val_index[0]]\n","        val_sub = train_val_data[val_index[0]:val_index[-1]+1]\n","        train_total.append(np.concatenate((train_sub_0,train_sub_1),axis=0))\n","        val_total.append(val_sub)\n","\n","        train_label_sub_0 = train_val_label[val_index[-1]+1:]\n","        train_label_sub_1 = train_val_label[:val_index[0]]\n","        val_label_sub = train_val_label[val_index[0]:val_index[-1]+1]\n","        train_label_total.append(np.concatenate((train_label_sub_0,train_label_sub_1),axis=0))\n","        val_label_total.append(val_label_sub)\n","    print('number of dataset:',len(val_total))\n","    return train_total,train_label_total,val_total,val_label_total"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#x_train_, y_train_,x_val_, y_val_ =  SelfKFold(raw_train)\n","x_train_ = raw_train.drop('label',axis = 1).values\n","#x_train_test = raw_test.drop('id',axis = 1).values\n","#x_train_ = np.concatenate([x_train_,x_train_test],axis=0)\n","y_train_ = raw_train['label'].values\n","#y_train_ = np.concatenate([y_train_,results5000],axis=0)\n","print(x_train_.shape)\n","print(y_train_.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for j in range(nets):\n","    model[j] = Sequential([\n","        Conv2D(64, (3,3), padding='same', input_shape=(28, 28, 1)),\n","        BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n","        LeakyReLU(alpha=0.1),\n","        Conv2D(64,  (3,3), padding='same'),\n","        BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n","        LeakyReLU(alpha=0.1),\n","        Conv2D(64,  (3,3), padding='same'),\n","        BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n","        LeakyReLU(alpha=0.1),\n","\n","        MaxPooling2D(2, 2),\n","        Dropout(0.25),\n","\n","        Conv2D(128, (3,3), padding='same'),\n","        BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n","        LeakyReLU(alpha=0.1),\n","        Conv2D(128, (3,3), padding='same'),\n","        BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n","        LeakyReLU(alpha=0.1),\n","        Conv2D(128, (3,3), padding='same'),\n","        BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n","        LeakyReLU(alpha=0.1),\n","\n","        MaxPooling2D(2,2),\n","        Dropout(0.25),    \n","\n","        Conv2D(256, (3,3), padding='same'),\n","        BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n","        LeakyReLU(alpha=0.1),\n","        Conv2D(256, (3,3), padding='same'),\n","        BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),##\n","        LeakyReLU(alpha=0.1),\n","\n","        MaxPooling2D(2,2),\n","        Dropout(0.25),\n","\n","\n","        Flatten(),\n","        Dense(256),\n","        LeakyReLU(alpha=0.1),\n","\n","        BatchNormalization(),\n","        Dense(10, activation='softmax')\n","    ])\n","    model[j].summary()\n","    optimizer = RMSprop(lr=0.0025)\n","    model[j].compile(loss= keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n","              optimizer=optimizer,\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["batch_size = 1024\n","num_classes = 10\n","epochs = 56\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["datagen_train = ImageDataGenerator(rotation_range = 20,\n","                                   width_shift_range = 0.25,\n","                                   height_shift_range = 0.25,\n","                                   shear_range = 10,\n","                                   zoom_range = 0.40,\n","                                   horizontal_flip = False)\n","\n","datagen_val = ImageDataGenerator() \n","def schedule(epoch):\n","    if epoch >= 52:\n","        lr = 1e-5\n","    elif epoch >= 48:\n","        lr = 0.0025 * 0.25 * 0.25 * 0.25\n","    elif epoch >= 43:\n","        lr = 0.0025 * 0.25 * 0.25\n","    elif epoch >= 35:\n","        lr = 0.0025 * 0.25\n","    else:\n","        lr = 0.0025\n","    return lr\n","\n","learning_rate_reduction = tf.keras.callbacks.LearningRateScheduler(schedule, verbose=1)\n","\n","#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4, restore_best_weights=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for j in range(nets):\n","    loadmodelname = \"../input/keras_version_code/weights_N_\" + str(j)\n","    model[j].load_weights(loadmodelname)\n","    savemodelname = \"/kaggle/working/weights_N_\" + str(j)\n","    model[j].save_weights(savemodelname)\n","    print(\"Saving\", loadmodelname, \"back to\", savemodelname)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["nets2train = 0\n","history = [0] * nets2train\n","for j in range(nets2train):\n","    x_train = x_train_.reshape(-1, 28, 28,1).astype('float32') / 255\n","    #print(x_train.shape)\n","    #x_val = x_val_[j].reshape(-1, 28, 28,1).astype('float32') / 255\n","    x_val = x_train[:1024,:,:,:]\n","    y_train = to_categorical(y_train_)\n","    #y_val = to_categorical(y_val_[j])\n","    y_val = y_train[:1024,:]\n","    #print(y_train.shape)\n","    modelfilename = \"weights_N_\" + str(j)\n","    checkpoint = ModelCheckpoint(modelfilename, monitor='acc', verbose=0, save_best_only=False, save_weights_only=False, period=epochs)\n","    history[j] = model[j].fit_generator(datagen_train.flow(x_train, y_train, batch_size=batch_size),\n","                              steps_per_epoch=len(x_train)//batch_size,\n","                              epochs=epochs,\n","                              validation_data=(x_val, y_val),\n","                              validation_steps=1,\n","                              callbacks=[learning_rate_reduction,checkpoint],\n","                              verbose=2)\n","    print(\"CNN\", j,\": Training done.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# for j in range(nets):\n","#     loadmodelname = \"../input/kannada-mnist-cnn-tutorial-with-app-top-2/weights_N\" + str(j)\n","#     model[j].load_weights(loadmodelname)\n","#     savemodelname = \"/kaggle/working/weights_N\" + str(j)\n","#     model[j].save_weights(savemodelname)\n","#     print(\"Saving\", loadmodelname, \"back to\", savemodelname)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test5000 = pd.read_csv(\"../input/Kannada-MNIST/test.csv\")\n","X_test5000 = test5000.drop(labels = [\"id\"],axis = 1)\n","X_test5000 = X_test5000 / 255.0\n","X_test5000 = X_test5000.values.reshape(-1,28,28,1)\n","TTA = 1\n","nets4predict = 5\n","datagen_test = [0]*TTA\n","results5000 = np.zeros( (X_test5000.shape[0], 10) ) \n","allthree = True\n","preds_tta = []\n","for each_test in range(TTA):\n","    if allthree :\n","        if each_test == 0:\n","            datagen_test[each_test] = ImageDataGenerator(#rotation_range = 10,\n","                                           #width_shift_range = 0.25,\n","                                           #height_shift_range = 0.25,\n","                                           #shear_range = 10,\n","                                           #zoom_range = 0.3,\n","                                           horizontal_flip = False,\n","               \n","                                           )\n","        elif each_test == 1:\n","            datagen_test[each_test] = ImageDataGenerator(rotation_range = 10,\n","                                           #width_shift_range = 0.25,\n","                                           #height_shift_range = 0.25,\n","                                           #shear_range = 10,\n","                                           #zoom_range = 0.4,\n","                                           horizontal_flip = False,\n","             \n","                                           )\n","        elif each_test == 2:\n","            datagen_test[each_test] = ImageDataGenerator(#rotation_range = 10,\n","                                           #width_shift_range = 0.25,\n","                                           #height_shift_range = 0.25,\n","                                           #shear_range = 10,\n","                                           zoom_range = 0.3,\n","                                           horizontal_flip = False,\n","               \n","                                           )\n","#         elif each_test == 3:\n","#             datagen_test[each_test] = ImageDataGenerator(rotation_range = 10,\n","#                                            #width_shift_range = 0.25,\n","#                                            #height_shift_range = 0.25,\n","#                                            #shear_range = 10,\n","#                                            #zoom_range = 0.4,\n","#                                            horizontal_flip = False,\n","                                                       \n","#                                            )\n","#         elif each_test == 4:\n","#             datagen_test[each_test] = ImageDataGenerator(#rotation_range = 10,\n","#                                            #width_shift_range = 0.25,\n","#                                            #height_shift_range = 0.25,\n","#                                            #shear_range = 10,\n","#                                            #zoom_range = 0.2,\n","#                                            horizontal_flip = False,\n","               \n","#                                            )\n","\n","        test_generator = datagen_test[each_test].flow(\n","                X_test5000,\n","                shuffle = False,\n","                #class_mode='categorical',\n","                batch_size=500)\n","        \n","        for j in range(nets4predict):\n","            print(\"CNN\",j)\n","            loadmodelname = \"weights_N_\" + str(j)\n","            model[j].load_weights(loadmodelname)\n","            test_generator.reset()\n","            preds = model[j].predict_generator(\n","                generator=test_generator,\n","                steps =int(X_test5000.shape[0]/500),\n","            )\n","            print(preds.shape)\n","            preds_tta.append(preds)\n","            \n","results5000 = np.mean(preds_tta,axis = 0)\n","results5000 = np.argmax(results5000,axis = 1)\n","\n","submission = pd.read_csv(\"../input/Kannada-MNIST/sample_submission.csv\")\n","submission['label'] = results5000\n","submission.to_csv(\"submission.csv\",index=False)\n","\n","print(\"DONE.\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}